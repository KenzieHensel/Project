{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, Binarizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = pd.read_csv('game_details_with_counts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                name  users_rated  average_rating  cult_classic\n",
      "0              CATAN       129246         7.09753             0\n",
      "1        Carcassonne       128379         7.41021             0\n",
      "2           Pandemic       126656         7.53305             0\n",
      "3          7 Wonders       105584         7.68019             0\n",
      "4  Terraforming Mars       100639         8.35596             1\n"
     ]
    }
   ],
   "source": [
    "# Creating the 'cult_classic' feature\n",
    "# Defining the thresholds for moderate ratings and high ratings\n",
    "moderate_ratings_threshold = 1000\n",
    "high_ratings_threshold = 8.0\n",
    "\n",
    "# Creating the 'cult_classic' feature\n",
    "data['cult_classic'] = ((data['users_rated'] > moderate_ratings_threshold) & \n",
    "                        (data['average_rating'] > high_ratings_threshold)).astype(int)\n",
    "\n",
    "# Checking the first few rows to confirm the new feature\n",
    "print(data[['name', 'users_rated', 'average_rating', 'cult_classic']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'year_published', 'min_players', 'max_players', 'min_playtime',\n",
      "       'max_playtime', 'min_age', 'categories', 'mechanics', 'users_rated',\n",
      "       'average_rating', 'weight', 'category_count', 'mechanic_count',\n",
      "       'cult_classic'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using integer-based features for MultinomialNB\n",
    "multinomial_features = data[['category_count', 'mechanic_count', 'min_players', 'max_players', 'min_playtime', 'max_playtime']].values\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    multinomial_features, data['cult_classic'], test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only continuous fields and scaling them\n",
    "gaussian_features = data[['year_published', 'weight', 'users_rated']].values\n",
    "scaler = StandardScaler()\n",
    "gaussian_features_scaled = scaler.fit_transform(gaussian_features)\n",
    "\n",
    "# Splitting dataset for Gaussian Naïve Bayes\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "    gaussian_features_scaled, data['cult_classic'], test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the 'popular_game' binary feature\n",
    "data['popular_game'] = (data['average_rating'] > 7).astype(int)\n",
    "\n",
    "# Creating a 'large_group' binary feature for games that support 4 or more players\n",
    "data['large_group'] = (data['max_players'] >= 4).astype(int)\n",
    "\n",
    "# Selecting the binary features for Bernoulli Naïve Bayes\n",
    "bernoulli_features = data[['popular_game', 'large_group']].values\n",
    "\n",
    "# Splitting dataset for Bernoulli Naïve Bayes\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    bernoulli_features, data['cult_classic'], test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naïve Bayes Results:\n",
      "Confusion Matrix:\n",
      " [[706  93]\n",
      " [ 59  42]]\n",
      "Accuracy: 0.8311111111111111\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       799\n",
      "           1       0.31      0.42      0.36       101\n",
      "\n",
      "    accuracy                           0.83       900\n",
      "   macro avg       0.62      0.65      0.63       900\n",
      "weighted avg       0.85      0.83      0.84       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naïve Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_m, y_train_m)\n",
    "y_pred_m = mnb.predict(X_test_m)\n",
    "print(\"Multinomial Naïve Bayes Results:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_m, y_pred_m))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_m, y_pred_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gaussian Naïve Bayes Results:\n",
      "Confusion Matrix:\n",
      " [[622 177]\n",
      " [ 23  78]]\n",
      "Accuracy: 0.7777777777777778\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.78      0.86       799\n",
      "           1       0.31      0.77      0.44       101\n",
      "\n",
      "    accuracy                           0.78       900\n",
      "   macro avg       0.64      0.78      0.65       900\n",
      "weighted avg       0.89      0.78      0.81       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naïve Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_g, y_train_g)\n",
    "y_pred_g = gnb.predict(X_test_g)\n",
    "print(\"\\nGaussian Naïve Bayes Results:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_g, y_pred_g))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_g, y_pred_g))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_g, y_pred_g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bernoulli Naïve Bayes Results:\n",
      "Confusion Matrix:\n",
      " [[799   0]\n",
      " [101   0]]\n",
      "Accuracy: 0.8877777777777778\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       799\n",
      "           1       0.00      0.00      0.00       101\n",
      "\n",
      "    accuracy                           0.89       900\n",
      "   macro avg       0.44      0.50      0.47       900\n",
      "weighted avg       0.79      0.89      0.84       900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naïve Bayes\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_b, y_train_b)\n",
    "y_pred_b = bnb.predict(X_test_b)\n",
    "print(\"\\nBernoulli Naïve Bayes Results:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_b, y_pred_b))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_b, y_pred_b))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_b, y_pred_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
