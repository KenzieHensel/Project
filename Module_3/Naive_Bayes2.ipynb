{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, Binarizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = pd.read_csv('game_details_with_counts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the 'cult_classic' feature\n",
    "# Cult classic: high ratings (> 8) and high number of ratings (> 1000)\n",
    "data['cult_classic'] = ((data['users_rated'] > 5000) & \n",
    "                        (data['average_rating'] > 8.0)).astype(int)\n",
    "\n",
    "# Creating the 'game_night_game' feature\n",
    "# Game night game: more than 4 players and high ratings (> 7)\n",
    "data['game_night_game'] = ((data['max_players'] >= 4) & (data['average_rating'] > 7)).astype(int)\n",
    "\n",
    "# Creating the 'high_complexity_game' feature\n",
    "# High complexity game: high weight (> 3.5), long playtime (> 60 mins), more than 4 categories, and more than 4 mechanics\n",
    "data['high_complexity_game'] = ((data['weight'] > 3.5) & \n",
    "                                 (data['max_playtime'] > 60) & \n",
    "                                 (data['category_count'] > 4) &\n",
    "                                 (data['mechanic_count'] > 4)).astype(int)\n",
    "\n",
    "# Creating the 'complexity_level' feature based on multiple factors\n",
    "# Low complexity: low weight, short playtime, few categories, few mechanics\n",
    "# Medium complexity: intermediate levels in criteria\n",
    "# High complexity: high weight, long playtime, multiple categories and mechanics\n",
    "conditions = [\n",
    "    (data['weight'] <= 2) & (data['max_playtime'] <= 30) & (data['category_count'] <= 2) & (data['mechanic_count'] <= 2),\n",
    "    (data['weight'] > 2) & (data['weight'] <= 3.5) & (data['max_playtime'] > 30) & (data['max_playtime'] <= 60) & \n",
    "    (data['category_count'] > 2) & (data['category_count'] <= 4) & (data['mechanic_count'] > 2) & (data['mechanic_count'] <= 4),\n",
    "    (data['weight'] > 3.5) & (data['max_playtime'] > 60) & (data['category_count'] > 4) & (data['mechanic_count'] > 4)\n",
    "]\n",
    "choices = ['low', 'medium', 'high']\n",
    "data['complexity_level'] = np.select(conditions, choices, default='medium')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'year_published', 'min_players', 'max_players', 'min_playtime',\n",
      "       'max_playtime', 'min_age', 'categories', 'mechanics', 'users_rated',\n",
      "       'average_rating', 'weight', 'category_count', 'mechanic_count',\n",
      "       'cult_classic', 'game_night_game', 'high_complexity_game',\n",
      "       'complexity_level'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naïve Bayes - Target: complexity_level\n",
    "multinomial_features = data[['weight', 'category_count', 'mechanic_count', 'min_players', 'max_players', 'min_playtime', 'max_playtime']].values\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "    multinomial_features, data['complexity_level'], test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naïve Bayes - Target: cult_classic\n",
    "gaussian_features = data[['weight', 'category_count', 'mechanic_count', 'min_players', 'max_players', 'min_playtime', 'max_playtime', 'users_rated', 'average_rating']].values\n",
    "scaler = StandardScaler()\n",
    "gaussian_features_scaled = scaler.fit_transform(gaussian_features)\n",
    "\n",
    "# Splitting dataset for Gaussian Naïve Bayes\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
    "    gaussian_features_scaled, data['cult_classic'], test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Naïve Bayes - Target: game_night_game\n",
    "bernoulli_features = data[['weight', 'category_count', 'mechanic_count', 'min_players', 'max_players', 'min_playtime', 'max_playtime']].values\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    bernoulli_features, data['game_night_game'], test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naïve Bayes Results (Complexity Level):\n",
      "Confusion Matrix:\n",
      " [[ 13   0  18]\n",
      " [  0  11   7]\n",
      " [ 67  75 709]]\n",
      "Accuracy: 0.8144444444444444\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        high       0.16      0.42      0.23        31\n",
      "         low       0.13      0.61      0.21        18\n",
      "      medium       0.97      0.83      0.89       851\n",
      "\n",
      "    accuracy                           0.81       900\n",
      "   macro avg       0.42      0.62      0.45       900\n",
      "weighted avg       0.92      0.81      0.86       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naïve Bayes - Complexity Level Prediction\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_m, y_train_m)\n",
    "y_pred_m = mnb.predict(X_test_m)\n",
    "print(\"Multinomial Naïve Bayes Results (Complexity Level):\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_m, y_pred_m))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_m, y_pred_m))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_m, y_pred_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gaussian Naïve Bayes Results (Cult Classic):\n",
      "Confusion Matrix:\n",
      " [[814  46]\n",
      " [ 12  28]]\n",
      "Accuracy: 0.9355555555555556\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       860\n",
      "           1       0.38      0.70      0.49        40\n",
      "\n",
      "    accuracy                           0.94       900\n",
      "   macro avg       0.68      0.82      0.73       900\n",
      "weighted avg       0.96      0.94      0.94       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naïve Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_g, y_train_g)\n",
    "y_pred_g = gnb.predict(X_test_g)\n",
    "print(\"\\nGaussian Naïve Bayes Results (Cult Classic):\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_g, y_pred_g))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_g, y_pred_g))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_g, y_pred_g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bernoulli Naïve Bayes Results (Game Night Game):\n",
      "Confusion Matrix:\n",
      " [[  0 398]\n",
      " [  0 502]]\n",
      "Accuracy: 0.5577777777777778\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       398\n",
      "           1       0.56      1.00      0.72       502\n",
      "\n",
      "    accuracy                           0.56       900\n",
      "   macro avg       0.28      0.50      0.36       900\n",
      "weighted avg       0.31      0.56      0.40       900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naïve Bayes\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_b, y_train_b)\n",
    "y_pred_b = bnb.predict(X_test_b)\n",
    "print(\"\\nBernoulli Naïve Bayes Results (Game Night Game):\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_b, y_pred_b))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_b, y_pred_b))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_b, y_pred_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Combine features and target into one DataFrame for resampling\n",
    "bernoulli_data = pd.DataFrame(X_train_b, columns=['weight', 'category_count', 'mechanic_count', 'min_players', 'max_players', 'min_playtime', 'max_playtime'])\n",
    "bernoulli_data['game_night_game'] = y_train_b\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_class = bernoulli_data[bernoulli_data['game_night_game'] == 0]\n",
    "minority_class = bernoulli_data[bernoulli_data['game_night_game'] == 1]\n",
    "\n",
    "# Oversample the minority class\n",
    "minority_class_oversampled = resample(minority_class, \n",
    "                                      replace=True,         # sample with replacement\n",
    "                                      n_samples=len(majority_class), # match number in majority class\n",
    "                                      random_state=42)      # reproducible results\n",
    "\n",
    "# Combine majority class with oversampled minority class\n",
    "balanced_data = pd.concat([majority_class, minority_class_oversampled])\n",
    "\n",
    "# Separate features and target for the balanced dataset\n",
    "X_train_b_balanced = balanced_data.drop('game_night_game', axis=1).values\n",
    "y_train_b_balanced = balanced_data['game_night_game'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bernoulli Naïve Bayes Results (Game Night Game) with Balanced Data:\n",
      "Confusion Matrix:\n",
      " [[  1 397]\n",
      " [  3 499]]\n",
      "Accuracy: 0.5555555555555556\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.00      0.00       398\n",
      "           1       0.56      0.99      0.71       502\n",
      "\n",
      "    accuracy                           0.56       900\n",
      "   macro avg       0.40      0.50      0.36       900\n",
      "weighted avg       0.42      0.56      0.40       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naïve Bayes with balanced data\n",
    "bnb = BernoulliNB(binarize=0.5)\n",
    "bnb.fit(X_train_b_balanced, y_train_b_balanced)\n",
    "y_pred_b = bnb.predict(X_test_b)\n",
    "print(\"\\nBernoulli Naïve Bayes Results (Game Night Game) with Balanced Data:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_b, y_pred_b))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_b, y_pred_b))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_b, y_pred_b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernoulli Naïve Bayes - Target: high_complexity_game\n",
    "bernoulli_features = data[['weight', 'category_count', 'mechanic_count', 'min_players', 'max_players', 'min_playtime', 'max_playtime']].values\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    bernoulli_features, data['high_complexity_game'], test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bernoulli Naïve Bayes Results (High Complexity Game):\n",
      "Confusion Matrix:\n",
      " [[869   0]\n",
      " [ 31   0]]\n",
      "Accuracy: 0.9655555555555555\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       869\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.97       900\n",
      "   macro avg       0.48      0.50      0.49       900\n",
      "weighted avg       0.93      0.97      0.95       900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naïve Bayes - High Complexity Game Prediction\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_b, y_train_b)\n",
    "y_pred_b = bnb.predict(X_test_b)\n",
    "print(\"\\nBernoulli Naïve Bayes Results (High Complexity Game):\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_b, y_pred_b))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_b, y_pred_b))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_b, y_pred_b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bernoulli Naïve Bayes Results (High Complexity Game) with Balanced Data:\n",
      "Confusion Matrix:\n",
      " [[865   4]\n",
      " [ 31   0]]\n",
      "Accuracy: 0.9611111111111111\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       869\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.96       900\n",
      "   macro avg       0.48      0.50      0.49       900\n",
      "weighted avg       0.93      0.96      0.95       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Combine features and target into one DataFrame for resampling\n",
    "bernoulli_data = pd.DataFrame(X_train_b, columns=['weight', 'category_count', 'mechanic_count', 'min_players', 'max_players', 'min_playtime', 'max_playtime'])\n",
    "bernoulli_data['high_complexity_game'] = y_train_b\n",
    "\n",
    "# Separate classes\n",
    "majority_class = bernoulli_data[bernoulli_data['high_complexity_game'] == 0]\n",
    "minority_class = bernoulli_data[bernoulli_data['high_complexity_game'] == 1]\n",
    "\n",
    "# Oversample the minority class\n",
    "minority_class_oversampled = resample(minority_class, \n",
    "                                      replace=True,         # sample with replacement\n",
    "                                      n_samples=len(majority_class), # match number in majority class\n",
    "                                      random_state=42)      # reproducible results\n",
    "\n",
    "# Combine majority class with oversampled minority class\n",
    "balanced_data = pd.concat([majority_class, minority_class_oversampled])\n",
    "\n",
    "# Separate features and target for the balanced dataset\n",
    "X_train_b_balanced = balanced_data.drop('high_complexity_game', axis=1).values\n",
    "y_train_b_balanced = balanced_data['high_complexity_game'].values\n",
    "\n",
    "# Bernoulli Naïve Bayes with balanced data\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_b_balanced, y_train_b_balanced)\n",
    "y_pred_b = bnb.predict(X_test_b)\n",
    "print(\"\\nBernoulli Naïve Bayes Results (High Complexity Game) with Balanced Data:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_b, y_pred_b))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_b, y_pred_b))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_b, y_pred_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bernoulli Naïve Bayes Results (Cult Classic - Original Data):"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      " [[860   0]\n",
      " [ 40   0]]\n",
      "Accuracy: 0.9555555555555556\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       860\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.96       900\n",
      "   macro avg       0.48      0.50      0.49       900\n",
      "weighted avg       0.91      0.96      0.93       900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\kenzi\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naïve Bayes - Target: cult_classic\n",
    "bernoulli_features = data[['weight', 'category_count', 'mechanic_count', 'min_players', 'max_players', 'min_playtime', 'max_playtime']].values\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "    bernoulli_features, data['cult_classic'], test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Bernoulli Naïve Bayes\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_b, y_train_b)\n",
    "y_pred_b = bnb.predict(X_test_b)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBernoulli Naïve Bayes Results (Cult Classic - Original Data):\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_b, y_pred_b))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_b, y_pred_b))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_b, y_pred_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
